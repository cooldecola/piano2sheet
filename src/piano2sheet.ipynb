{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics\n",
    "import mahotas       # Otsu thresholding\n",
    "import bisect        # Key insert point\n",
    "import imutils       # Crop and resize images\n",
    "import pandas as pd\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "import youtube_dl\n",
    "import os            # Folder paths\n",
    "import sys           # Exit function\n",
    "import glob          # Folder searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note class\n",
    "class Note: \n",
    "    def __init__(self, centroid_x, y_dot):\n",
    "        self.centroid_x = centroid_x\n",
    "        self.y_dot = y_dot\n",
    "\n",
    "# just  a function for printing images\n",
    "def display_img(title, img):\n",
    "    cv2.imshow(title, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "      \n",
    "# function for getting next note\n",
    "def getNextNote(first_note):\n",
    "    if \"#\" in first_note: \n",
    "        octave = first_note[2]\n",
    "        if first_note[:2] == \"A#\":\n",
    "            return (\"C#\" + octave)\n",
    "        elif first_note[:2] == \"C#\":\n",
    "            return (\"D#\" + octave)\n",
    "        elif first_note[:2] == \"D#\":\n",
    "            return (\"F#\" + octave)\n",
    "        elif first_note[:2] == \"F#\":\n",
    "            return (\"G#\" + octave)\n",
    "        elif first_note[:2] == \"G#\":\n",
    "            next_octave = int(octave) + 1\n",
    "            return (\"A#\" + str(next_octave))\n",
    "    \n",
    "    else: \n",
    "        octave = first_note[1]\n",
    "        if first_note[0] == \"A\":\n",
    "            return (\"B\" + octave)\n",
    "        elif first_note[0] == \"B\":\n",
    "            return (\"C\" + octave)\n",
    "        elif first_note[0] == \"C\":\n",
    "            return (\"D\" + octave)\n",
    "        elif first_note[0] == \"D\":\n",
    "            return (\"E\" + octave)\n",
    "        elif first_note[0] == \"E\":\n",
    "            return (\"F\" + octave)\n",
    "        elif first_note[0] == \"F\":\n",
    "            return (\"G\" + octave)\n",
    "        elif first_note[0] == \"G\":\n",
    "            next_octave = int(octave) + 1\n",
    "            return (\"A\" + str(next_octave))\n",
    "\n",
    "# Function for Gaussian Blurring\n",
    "def gaussianBlurring(gray_img, blur_sq, std_dev = 0):\n",
    "    return cv2.GaussianBlur(gray_img, (blur_sq, blur_sq), std_dev)\n",
    "\n",
    "# Function for Canny Edge Detection\n",
    "def cannyDetection(blurred_img, th1, th2, apertureSize = 3):\n",
    "    return cv2.Canny(blurred_img, th1, th2, apertureSize)\n",
    "\n",
    "# Function to return the top and bottom of the keyboard using HoughLines\n",
    "def keyboardYCoords(edged_img, rho = 1, theta = np.pi/180, threshold = None):\n",
    "    \n",
    "    if threshold is None:\n",
    "        threshold = edged_img.shape[1]//2 # half the width\n",
    "    \n",
    "    lines = cv2.HoughLines(edged_img, rho, theta, threshold) \n",
    "    y_cord = [] #the y-value of the lines generated from hough transform\n",
    "\n",
    "    #iterating through lines\n",
    "    for line in lines: \n",
    "        rho_l, theta_l = line[0]\n",
    "        a = np.cos(theta_l)\n",
    "        b = np.sin(theta_l)\n",
    "        x0 = a * rho_l\n",
    "        y0 = b * rho_l\n",
    "        y_cord.append(y0) #appending to list\n",
    "\n",
    "    y_cord.sort(reverse=True)\n",
    "    return y_cord[0:2]\n",
    "\n",
    "# Function to threshold an image\n",
    "def threshold(gray_img, th1 = 90, th2 = 150, thresh_type = cv2.THRESH_BINARY_INV):\n",
    "    _, threshed_img = cv2.threshold(gray_img, th1, th2, thresh_type)\n",
    "    return threshed_img\n",
    "\n",
    "\n",
    "        \n",
    "# Function for doing connected components\n",
    "def connectedComponents(binarized_img, connectivity = 8, ltype = cv2.CV_32S):\n",
    "    output = cv2.connectedComponentsWithStats(binarized_img, connectivity, cv2.CV_32S)\n",
    "    num_labels = output[0]\n",
    "    labels = output[1]\n",
    "    stats = output[2]\n",
    "    centroids = output[3]\n",
    "\n",
    "    return [num_labels, labels, stats, centroids]\n",
    "\n",
    "\n",
    "# Function to calculate the centroids of detected connected components\n",
    "#   This should be used for the 36 black keys and 52 white keys\n",
    "#   use display_result = True to display the results on the source image\n",
    "def keyDetection(orig_img, num_labels, labels, stats, centroids, min_key_area = 100, display_result = False):\n",
    "    final_labels = []\n",
    "\n",
    "    output_img = orig_img.copy()\n",
    "\n",
    "    # Loop through the detected connected components\n",
    "    for i in range(1, num_labels):\n",
    "        [x,y,w,h,area] = getConnectedComponentRectangle(stats[i,:])\n",
    "        (cX, cY) = centroids[i]\n",
    "        \n",
    "        # Consider only connected that have an area greater than min_key_area pixels\n",
    "        if (min_key_area < area < np.inf):\n",
    "            final_labels.append([i,cX])\n",
    "            \n",
    "            # Display on original image\n",
    "            if (display_result):\n",
    "                cv2.rectangle(output_img, (x,y), (x+w, y+h), (255,0,0),1)\n",
    "                cv2.circle(output_img, (int(cX), int(cY)), 4, (255,255,0), -1)\n",
    "#                 componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "                cv2.imshow(\"Output\", output_img)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "    key_width = statistics.median(stats[:, cv2.CC_STAT_WIDTH])\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    #Return the centroid of the processed connected components and the median width\n",
    "    return final_labels, key_width\n",
    "\n",
    "# Get the x,y coordinates and width + height of cv2.connectedcomponents output\n",
    "#    Given the i-th components of the stats matrix (an N x 5 matrix)\n",
    "def getConnectedComponentRectangle(ith_stats):\n",
    "        x = ith_stats[cv2.CC_STAT_LEFT]\n",
    "        y = ith_stats[cv2.CC_STAT_TOP]\n",
    "        w = ith_stats[cv2.CC_STAT_WIDTH]\n",
    "        h = ith_stats[cv2.CC_STAT_HEIGHT]\n",
    "        area = ith_stats[cv2.CC_STAT_AREA]\n",
    "        \n",
    "        return [x,y,w,h,area]\n",
    "\n",
    "\n",
    "def displayCentroid(key_list, img):\n",
    "    y = img.shape[0]*3//4\n",
    "    for (note, centroid) in key_list: \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        line = cv2.line(img,(int(centroid),0),(int(centroid),900),(0,0,255),1)\n",
    "        text_label = cv2.putText(img, note, (int(centroid), y), font, 0.5, (0,255,0), 1)\n",
    "        cv2.imshow(\"Key Label\", img)\n",
    "        cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Given an x-coordinate, return the appropriate insertion point in the keyboard\n",
    "def key_pressed(key_list, key_index):\n",
    "    insertion_point = bisect.bisect_left(key_list[:,1].astype(float),key_index)\n",
    "    \n",
    "    #Insertion outside our index, means to insert it at the end (return the last key)\n",
    "    if insertion_point >= len(key_list):\n",
    "        insertion_point = len(key_list)-1\n",
    "#     print(insertion_point)\n",
    "#     print('You pressed the {} key.'.format(key_list[insertion_point,0]))\n",
    "\n",
    "    note = key_list[insertion_point,0]\n",
    "    index = insertion_point\n",
    "\n",
    "    return note, index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def timeNotes(ith_centroids, y_offset, note_height, keyboard_line, keyboard_array, keys_timed_update, \n",
    "              elapsed, output_img, font = cv2.FONT_HERSHEY_SIMPLEX, font_scale = 0.5, font_color = (0,0,255)):\n",
    "    # ith_centroids - the centroid of a given note (i.e. an x,y pair)\n",
    "    # y_offset - if the keyboard has been offset in the y direction (this allows the detection to stay out of the top/bottom edges)\n",
    "    # note_height - from connectedcomponents\n",
    "    # keyboard_line - the y-coordinate that serves as the threshold/line to calculate press down/up\n",
    "    # keyboard_array - the matrix of keyboard notes/octaves and x-coordinates\n",
    "    # key_timed_update - our array that holds on/off button for each note in our keyboard\n",
    "    # elapsed - time in seconds\n",
    "    # output_img - the screen we want to display to\n",
    "\n",
    "    lag = 2 # number of pixels about the keyboard_line for detection\n",
    "    \n",
    "    # Get centroid of detected note\n",
    "    (cX, cY) = ith_centroids\n",
    "    cY = cY + y_offset # We cropped out the first 20 pixels\n",
    "\n",
    "    # Y-coordinate of top and bottom edges of a note (this is truncated by the \"size\" of the detection area)\n",
    "    dist_to_edge = note_height/2 #getting the distance from centroid to bottom edge for better detection later on\n",
    "    top_dot = cY-dist_to_edge\n",
    "    bottom_dot = cY+dist_to_edge\n",
    "\n",
    "#     note = Note(cX, cY+dist_to_edge) #creating note object and adding to list\n",
    "\n",
    "    if ( (int(bottom_dot) >= int(keyboard_line - lag)) and (int(bottom_dot) <= int(keyboard_line)) ):\n",
    "        note_played, index = key_pressed(keyboard_array, cX)\n",
    "        keys_timed_update[index].append([elapsed])\n",
    "#         print(note_played)\n",
    "#         print('='*50)\n",
    "\n",
    "    if ( (int(top_dot) >= int(keyboard_line - lag)) and (int(top_dot) <= int(keyboard_line)) ):\n",
    "        note_played, index = key_pressed(keyboard_array, cX)\n",
    "        keys_timed_update[index].append([elapsed])\n",
    "\n",
    "    note_played, _ = key_pressed(keyboard_array, cX)\n",
    "    cv2.line(output_img, (0, int(keyboard_line)), (600, int(keyboard_line)), (0,0,255), 2)\n",
    "    cv2.rectangle(output_img, (x,y), (x+w, y+h), font_color,1)\n",
    "    cv2.circle(output_img, (int(cX), int(bottom_dot)), 1, (0,122,255), 3)\n",
    "    cv2.circle(output_img, (int(cX), int(top_dot)), 1, (0,122,255), 3)\n",
    "    cv2.putText(output_img, note_played, (int(cX), int(cY+dist_to_edge)), font, font_scale, font_color, 1)\n",
    "    \n",
    "    return keys_timed_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ask user for YouTube link\n",
    "- Download (?) video (or atleast a temporary copy)\n",
    "- Using the first few frames, detect the keyboard\n",
    "    - If 72 keys are not detected, try next few frames and repeat\n",
    "    - If they can't be detected at all, end program\n",
    "- Label black and white keys\n",
    "- Run algorithm, get array with start/end times for each note\n",
    "- Convert to .midi\n",
    "- Convert to sheet music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keyboard: \n",
    "    def __init__(self, youtubeURL):\n",
    "        self.youtubeURL = youtubeURL\n",
    "        \n",
    "    # For downloading YouTube videos\n",
    "    def my_hook(self, d):\n",
    "        if d['status'] == 'finished':\n",
    "            print('Download complete.')\n",
    "        elif d['status'] == 'error':\n",
    "            print('Error in downloading file - exiting program!')\n",
    "            sys.exit()\n",
    "            \n",
    "    # Remove previously downloaded file\n",
    "    def clear_previous(self, path = \"./videos/video_to_process*\"):\n",
    "        vtp = glob.glob(path)\n",
    "        if vtp:\n",
    "            camera = cv2.VideoCapture(vtp[0])\n",
    "            camera.release()\n",
    "            os.remove(vtp[0])\n",
    "\n",
    "    # Function to download a YouTube video\n",
    "    def downloadYouTube(self, path = './videos/video_to_process.%(ext)s', quiet = True):\n",
    "    \n",
    "        self.clear_previous()\n",
    "    \n",
    "        ydl_opts = {'outtmpl': path,\n",
    "                   'quiet': quiet,\n",
    "                   'progress_hooks': [self.my_hook]}\n",
    "        try:\n",
    "            with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "                print('Downloading video...')\n",
    "                ydl.download([self.youtubeURL])\n",
    "        except youtube_dl.utils.DownloadError:\n",
    "            print('Exiting program!')\n",
    "            \n",
    "    # Use the file called video_to_process and detect our 88 keys\n",
    "    def detect_keys(self, resize_width, bl_blur_sq, bl_canny_th1, bl_canny_th2, bl_thresh1, bl_thresh2,\n",
    "                wh_blur_sq, path = \"./videos/video_to_process*\",num_bl_keys = 36, num_wh_keys = 52):\n",
    "        vtp = glob.glob(path)\n",
    "        if vtp:\n",
    "            camera = cv2.VideoCapture(vtp[0])\n",
    "            # Could not access the file\n",
    "            if not camera.isOpened():\n",
    "                print('Error - video file could not be read!')\n",
    "                sys.exit()\n",
    "            # Process video\n",
    "            else:\n",
    "                print('Detecting keys...')\n",
    "                while True:\n",
    "                    #grabbed is a boolean than tells us if there is a valid frame\n",
    "                    (grabbed, frame) = camera.read()\n",
    "                    if not grabbed:\n",
    "                        break\n",
    "\n",
    "                    frame = imutils.resize(frame,width = resize_width)\n",
    "\n",
    "                    # Get the bottom-half of the frame (where the keyboard lies) and process from here\n",
    "#                     keys = frame[frame.shape[0]//2:,:]\n",
    "#                     gray_keys = cv2.cvtColor(keys, cv2.COLOR_BGR2GRAY)\n",
    "                    keys = frame\n",
    "                    gray_keys = cv2.cvtColor(keys, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Process\n",
    "                    blurred = gaussianBlurring(gray_keys, blur_sq = bl_blur_sq)\n",
    "                    edges = cannyDetection(blurred, th1 = bl_canny_th1, th2 = bl_canny_th2)\n",
    "\n",
    "                    # Crop\n",
    "                    crop_coordinates  = keyboardYCoords(edges)\n",
    "                    keyboard.y_coords = crop_coordinates\n",
    "                    cropped_keys      = keys[int(crop_coordinates[1])+20:int(crop_coordinates[0])]\n",
    "                    cropped_gray_keys = gray_keys[int(crop_coordinates[1])+20:int(crop_coordinates[0])]\n",
    "\n",
    "                    # Labels keys\n",
    "                    thresh_keys_bl = threshold(cropped_gray_keys, th1 = bl_thresh1, th2 = bl_thresh2)\n",
    "\n",
    "                    # Black keys\n",
    "                    [num_labels_bl, labels_bl, stats_bl, centroids_bl] = connectedComponents(binarized_img = thresh_keys_bl)\n",
    "                    final_labels_bl, key_width_bl = keyDetection(cropped_keys, num_labels_bl, labels_bl, stats_bl, centroids_bl)\n",
    "                    if len(final_labels_bl) == num_bl_keys: \n",
    "                        first_note = \"A#0\"\n",
    "                        for i in range(num_bl_keys):\n",
    "                            final_labels_bl[i][0] = first_note\n",
    "                            first_note = getNextNote(first_note)\n",
    "\n",
    "                        final_labels_bl = sorted(final_labels_bl, key=lambda x: x[1])\n",
    "\n",
    "                    # White keys\n",
    "                    blurred_w = gaussianBlurring(cropped_gray_keys, blur_sq = wh_blur_sq)\n",
    "                    T = mahotas.thresholding.otsu(blurred_w)*1.3\n",
    "                    thresh_keys_w = cropped_gray_keys.copy()\n",
    "                    thresh_keys_w[thresh_keys_w>T] = 255\n",
    "                    thresh_keys_w[thresh_keys_w<T] = 0\n",
    "                    [num_labels_w, labels_w, stats_w, centroids_w] = connectedComponents(binarized_img = thresh_keys_w)\n",
    "                    final_labels_w, key_width_w = keyDetection(cropped_keys, num_labels_w, labels_w, stats_w, centroids_w)\n",
    "\n",
    "                    if len(final_labels_w) == num_wh_keys: \n",
    "                        first_note = \"A0\"\n",
    "                        for j in range(num_wh_keys):\n",
    "                            final_labels_w[j][0] = first_note\n",
    "                            first_note = getNextNote(first_note)\n",
    "\n",
    "                        final_labels_w = sorted(final_labels_w, key=lambda x: x[1])\n",
    "\n",
    "                    # Determine if they sum to 88 keys (36 black, 52 white) - if not, try next frame\n",
    "                    if len(final_labels_bl) == num_bl_keys and len(final_labels_w) == num_wh_keys:\n",
    "                        self.black_keys = final_labels_bl\n",
    "                        self.white_keys = final_labels_w\n",
    "                        self.black_width = key_width_bl\n",
    "                        self.white_width = key_width_w\n",
    "                        self.keyboard_img = frame\n",
    "                        camera.release()         # Release cv2 camera object\n",
    "                        cv2.destroyAllWindows()  # Destroy any cv2 windows\n",
    "                        print('Key detection complete.')\n",
    "                        break\n",
    "\n",
    "                #     #Show the frame + drawn rectangle\n",
    "                #     cv2.imshow(\"Face\", thresh_keys_bl)\n",
    "\n",
    "    #                 #Can break early by pressing \"q\"\n",
    "    #                 if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    #                     break\n",
    "\n",
    "            # If at this point we've looped through everything and we don't have 72 keys\n",
    "            camera.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            if len(final_labels_bl) != 36 and len(final_labels_w) != 52:\n",
    "                print('Error in processing file - exiting program!')\n",
    "                sys.exit()\n",
    "                \n",
    "                \n",
    "                \n",
    "        # Glob did not find a valid file\n",
    "        else:\n",
    "            print('Error - video path could not be accessed!')\n",
    "            sys.exit()\n",
    "            \n",
    "            \n",
    "            \n",
    "    # Assign end-of-range for each key\n",
    "    def key_ranges(self):\n",
    "\n",
    "        # Array\n",
    "        full_key_list = self.black_keys + self.white_keys\n",
    "        full_key_list = sorted(full_key_list, key=lambda x: x[1].astype(float))\n",
    "        full_key_list = np.array(full_key_list)\n",
    "\n",
    "        # Empty list\n",
    "        tmp_list = np.empty([len(full_key_list), 2], dtype='object')\n",
    "\n",
    "        # Loop through and assign end-of-range for each key\n",
    "        # CASE: white key adjacent to black key: end of the white key range is the adjacent black key's centroid - black/2\n",
    "        #       black key:                       end of the black key range is the black key's centroid + black/2\n",
    "        #       white key adjacent to white key: end of the white key range is the half-way point between the adjacent centroids\n",
    "        for i in range(0,len(full_key_list)-1):\n",
    "            if len(full_key_list[i,0])==1 and len(full_key_list[i+1,0])>1: # White adjacent to black\n",
    "                tmp_list[i,1] = full_key_list[i+1,1].astype(float) - self.black_width/2\n",
    "            elif len(full_key_list[i,0])>1: # Black key\n",
    "                tmp_list[i,1] = full_key_list[i,1].astype(float) + self.black_width/2\n",
    "            else: # White key adjacent to white key\n",
    "                tmp_list[i,1] = (full_key_list[i,1].astype(float)+ full_key_list[i+1,1].astype(float))/2\n",
    "\n",
    "            # No change to the actual note (only the distances, above) for the first key\n",
    "            tmp_list[i,0] = full_key_list[i,0]\n",
    "\n",
    "        #For the last key, just take it to infinity\n",
    "        tmp_list[-1,1] = np.inf\n",
    "        tmp_list[-1,0] = full_key_list[-1,0]\n",
    "\n",
    "        full_key_list = tmp_list\n",
    "\n",
    "        self.keyboard_array = full_key_list\n",
    "            \n",
    "    \n",
    "    # Return the centroid of the black/white keys alongside the median width of each\n",
    "    def getKeys(self):\n",
    "        return [self.black_keys, self.white_keys, self.black_width, self.white_width]\n",
    "    \n",
    "    # Return the frame that 88 keys were successfully identified from\n",
    "    def getFrame(self):\n",
    "        return self.keyboard_img\n",
    "    \n",
    "    def getFullKeyList(self):\n",
    "        return self.keyboard_array\n",
    "    \n",
    "    def getKeyboardYCoords(self):\n",
    "        return keyboard.y_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting keys...\n",
      "Key detection complete.\n"
     ]
    }
   ],
   "source": [
    "#Download a YouTube video and process it to determine where the centroid of the black and white keys are\n",
    "keyboard = Keyboard('https://www.youtube.com/watch?v=skFugVOqBM4')\n",
    "# keyboard.downloadYouTube()\n",
    "keyboard.detect_keys(resize_width = 600, bl_blur_sq = 5, bl_canny_th1 = 200, bl_canny_th2 = 200, \n",
    "                    bl_thresh1 = 90, bl_thresh2 = 150, wh_blur_sq = 7)\n",
    "keyboard.key_ranges()\n",
    "\n",
    "[black, white, black_width, white_width] = keyboard.getKeys()     # Array of keys\n",
    "key_img = keyboard.getFrame()                                     # Image of video used to detect our 88 keys\n",
    "keyboard_array = keyboard.getFullKeyList()                        # Combined array of keys\n",
    "keyboard_y_coords = keyboard.getKeyboardYCoords()                 # y[0] is the bottom of the keyboard, y[1] is the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[331.0, 268.0]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keyboard_y_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.imshow(key_img)\n",
    "# displayCentroid(white, key_img.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['A0', 8.248157248157248],\n",
       "       ['A#0', 16.363636363636363],\n",
       "       ['B0', 21.35514018691589],\n",
       "       ['C0', 30.73469387755102],\n",
       "       ['C#0', 36.515625],\n",
       "       ['D0', 43.51020408163265],\n",
       "       ['D#0', 50.484375],\n",
       "       ['E0', 55.393081761006286],\n",
       "       ['F0', 65.71260997067449],\n",
       "       ['F#0', 71.515625],\n",
       "       ['G0', 77.83985765124555],\n",
       "       ['G#0', 83.50393700787401],\n",
       "       ['A1', 89.6822429906542],\n",
       "       ['A#1', 96.484375],\n",
       "       ['B1', 101.73578595317726],\n",
       "       ['C1', 111.7280701754386],\n",
       "       ['C#1', 117.50393700787401],\n",
       "       ['D1', 123.90615835777126],\n",
       "       ['D#1', 131.48818897637796],\n",
       "       ['E1', 136.371875],\n",
       "       ['F1', 146.5943396226415],\n",
       "       ['F#1', 151.515625],\n",
       "       ['G1', 158.328125],\n",
       "       ['G#1', 164.5],\n",
       "       ['A2', 170.36789297658862],\n",
       "       ['A#2', 177.48818897637796],\n",
       "       ['B2', 182.371875],\n",
       "       ['C2', 192.628125],\n",
       "       ['C#2', 197.515625],\n",
       "       ['D2', 204.51020408163265],\n",
       "       ['D#2', 211.48818897637796],\n",
       "       ['E2', 216.73578595317727],\n",
       "       ['F2', 226.7280701754386],\n",
       "       ['F#2', 232.515625],\n",
       "       ['G2', 239.31347962382446],\n",
       "       ['G#2', 244.95890410958904],\n",
       "       ['A3', 250.8160535117057],\n",
       "       ['A#3', 257.484375],\n",
       "       ['B3', 263.2719298245614],\n",
       "       ['C3', 272.7280701754386],\n",
       "       ['C#3', 278.515625],\n",
       "       ['D3', 285.4868035190616],\n",
       "       ['D#3', 292.48818897637796],\n",
       "       ['E3', 297.37617554858934],\n",
       "       ['F3', 307.2890365448505],\n",
       "       ['F#3', 312.515625],\n",
       "       ['G3', 319.35],\n",
       "       ['G#3', 325.5],\n",
       "       ['A4', 331.65830721003135],\n",
       "       ['A#4', 338.48818897637796],\n",
       "       ['B4', 343.37617554858934],\n",
       "       ['C4', 353.628125],\n",
       "       ['C#4', 359.33076923076925],\n",
       "       ['D4', 365.5233918128655],\n",
       "       ['D#4', 372.484375],\n",
       "       ['E4', 378.2719298245614],\n",
       "       ['F4', 387.7280701754386],\n",
       "       ['F#4', 393.515625],\n",
       "       ['G4', 400.31347962382443],\n",
       "       ['G#4', 406.496062992126],\n",
       "       ['A5', 411.81605351170566],\n",
       "       ['A#5', 418.53846153846155],\n",
       "       ['B5', 424.2719298245614],\n",
       "       ['C5', 434.04761904761904],\n",
       "       ['C#5', 439.515625],\n",
       "       ['D5', 446.5],\n",
       "       ['D#5', 453.48818897637796],\n",
       "       ['E5', 458.37617554858934],\n",
       "       ['F5', 468.71260997067446],\n",
       "       ['F#5', 474.3622047244094],\n",
       "       ['G5', 480.5150501672241],\n",
       "       ['G#5', 486.5],\n",
       "       ['A6', 492.671875],\n",
       "       ['A#6', 499.48818897637796],\n",
       "       ['B6', 504.37617554858934],\n",
       "       ['C6', 514.7126099706745],\n",
       "       ['C#6', 520.515625],\n",
       "       ['D6', 527.195652173913],\n",
       "       ['D#6', 534.3230769230769],\n",
       "       ['E6', 539.3551401869158],\n",
       "       ['F6', 549.27],\n",
       "       ['F#6', 554.515625],\n",
       "       ['G6', 561.3134796238245],\n",
       "       ['G#6', 567.496062992126],\n",
       "       ['A7', 573.0313479623825],\n",
       "       ['A#7', 580.4609375],\n",
       "       ['B7', 585.371875],\n",
       "       ['C7', inf]], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keyboard_array\n",
    "#Find the appropriate index for any given centroid via:\n",
    "# note, index = key_pressed(full_key_list, 999)\n",
    "# print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to delete the processed video\n",
    "# keyboard.clear_previous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGNORE BELOW THIS LINE ##########################\n",
    "___________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing with Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sample piano image from  youtube\n",
    "# img_notes = cv2.imread(\"images/IMG_very_close_notes.png\")\n",
    "\n",
    "# #converting to gray\n",
    "# gray_notes = cv2.cvtColor(img_notes, cv2.COLOR_BGR2GRAY)\n",
    "# img_notes_rgb = cv2.cvtColor(img_notes, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# plt.imshow(img_notes_rgb)\n",
    "# # plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*y_cord[1]* is the position of the top of the keyboard. We calculated this using **half** the original image, so we need to add this back in.\n",
    "\n",
    "# I added it back paps =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Cropped\n",
    "# top_keys_index = y_cord[1] + img_notes.shape[0]//2\n",
    "# crop_img_notes = img_notes[20:(int(top_keys_index)-30)] #Crop the top 20 pixels and bottom 30\n",
    "\n",
    "# plt.imshow(crop_img_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_img_notes_gray = cv2.cvtColor(crop_img_notes, cv2.COLOR_BGR2GRAY)\n",
    "# # # k = 3\n",
    "# # # blurred = cv2.GaussianBlur(crop_img_notes_gray, (k,k), 0)\n",
    "\n",
    "# # #Using standard threshold to create contrast between white/black keys\n",
    "# # _, th_notes = cv2.threshold(blurred, 90, 150, cv2.THRESH_BINARY)\n",
    "\n",
    "# _, th_notes = cv2.threshold(crop_img_notes_gray, 90, 150, cv2.THRESH_BINARY)\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(th_notes, cmap = \"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #####################################################################################\n",
    "# ####### using connected component detection algorithm to separate all the black notes\n",
    "# connectivity = 1\n",
    "# output = cv2.connectedComponentsWithStats(th_notes, connectivity, cv2.CV_32S)\n",
    "# num_labels = output[0]\n",
    "# labels = output[1]\n",
    "# stats = output[2]\n",
    "# centroids = output[3]\n",
    "\n",
    "# final_labels = []\n",
    "# note_list = [] #creating a list of all the relavent notes. \n",
    "\n",
    "\n",
    "# output = img_notes_rgb.copy()\n",
    "# font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# #For loop only used for displaying \n",
    "# for i in range(1, num_labels):\n",
    "#     x = stats[i, cv2.CC_STAT_LEFT]\n",
    "#     y = stats[i, cv2.CC_STAT_TOP] + 20 # We cropped out the first 20 pixels\n",
    "#     w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "#     h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "#     area = stats[i, cv2.CC_STAT_AREA]\n",
    "#     (cX, cY) = centroids[i]\n",
    "#     cY = cY + 20 # We cropped out the first 20 pixels\n",
    "#     if (20 < area < np.inf): #filtering out relavent detections (the ones big enough to be black keys)\n",
    "#         final_labels.append(i)\n",
    "#         cv2.rectangle(output, (x,y), (x+w, y+h), (255,0,0),1)\n",
    "#         dist_to_edge = h/2 #getting the distance from centroid to bottom edge for better detection later on\n",
    "#         cv2.circle(output, (int(cX), int(cY+dist_to_edge)), 1, (0,122,255), 3)\n",
    "#         componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "        \n",
    "#         note = Note(cX, cY+dist_to_edge) #creating note object and adding to list\n",
    "#         note_list.append(note)\n",
    "        \n",
    "#         note_played, _ = key_pressed(full_key_list, note.centroid_x)\n",
    "#         cv2.putText(output, note_played, (int(note.centroid_x), int(note.y_dot)), font, 0.5, (0,255,0), 1)\n",
    "\n",
    "# #         display_img(\"Output\", output)\n",
    "# #         display_img(\"Connected Component\", componentMask)\n",
    "# #         cv2.waitKey(0)\n",
    "\n",
    "# # print(final_labels)\n",
    "# # cv2.destroyAllWindows()\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(output)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture('videos/Moonlight Sonata 1st Movement  Opus 27 No 2_Trim.mp4')\n",
    "\n",
    "frames = camera.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "seconds_per_frame = fps/frames\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "\n",
    "notes_pressed = []\n",
    "\n",
    "keys_timed = []\n",
    "for x in keyboard_array:\n",
    "    keys_timed.append([x[0]])\n",
    "\n",
    "\n",
    "keys_timed_update = []\n",
    "for x in keyboard_array:\n",
    "    keys_timed_update.append([x[0]])\n",
    "\n",
    "\n",
    "\n",
    "while (camera.isOpened()):    \n",
    "    #grabbed is a boolean than tells us if there is a valid frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "\n",
    "    frame_number = camera.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    elapsed = frame_number/fps\n",
    "\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    counter += seconds_per_frame        \n",
    "         \n",
    "    #!!! - width\n",
    "    frame = imutils.resize(frame,width = 600) #resize or else it won't work\n",
    "    \n",
    "    #!!! - keyboard_y_coords//40//20\n",
    "    crop_frame = frame[20:int(keyboard_y_coords[1])-40] #Crop the top 20 pixels and bottom 50\n",
    "    \n",
    "    # threshold the cropped and grayed image\n",
    "    crop_frame_gray = cv2.cvtColor(crop_frame, cv2.COLOR_BGR2GRAY)\n",
    "    th_crop_frame = threshold(crop_frame_gray, thresh_type = cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "    # We have a thresholded image for use to use ConnectedComponents on\n",
    "    #####################################################################################\n",
    "    ####### using connected component detection algorithm to separate all the black notes    \n",
    "    [num_labels, labels, stats, centroids] = connectedComponents(th_crop_frame)\n",
    "    \n",
    "    # List of indices that we may have to remove - combined white/black key needs to be split\n",
    "    indices_to_pop = []\n",
    "\n",
    "    output_img = frame.copy()\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    \n",
    "    i=1\n",
    "    #Loop through all the connected components\n",
    "    while i < len(stats):\n",
    "\n",
    "        # Width of i-th connected component\n",
    "        curr_connected_comp = stats[i, cv2.CC_STAT_WIDTH]\n",
    "\n",
    "        # !!! - Determine if the WIDTH is much bigger than the width of a white key and less than 3x? (So we don't get extraneous video text, etc.)\n",
    "        if curr_connected_comp > white_width*1.25 and curr_connected_comp < white_width*3:\n",
    "            \n",
    "            #Threshold just the large component of interest\n",
    "            componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "            threshMask = cv2.bitwise_and(crop_frame_gray, crop_frame_gray, mask = componentMask) #Replace this with video frame\n",
    "\n",
    "            # Histogram segregation of black/white key\n",
    "            # Grayscale has one channel so we use [0]\n",
    "                #Possible values range from 0 to 256\n",
    "            bin_scaler = 4\n",
    "            hist = cv2.calcHist([threshMask], [0], None, [256/bin_scaler], [1, 256])\n",
    "\n",
    "            #Use a Histogram to compute the dominant non-black (i.e. not the background) colour. Use ~90% of this to threshold the image.\n",
    "            T = hist.argmax() * bin_scaler * .95\n",
    "            white_notes = threshMask.copy()\n",
    "            white_notes[white_notes>T] = 255\n",
    "            white_notes[white_notes<T] = 0\n",
    "\n",
    "            #Detect the first set of WHITE keys\n",
    "            [num_labels_wh, labels_wh, stats_wh, centroids_wh] = connectedComponents(white_notes)\n",
    "\n",
    "            #Loop through components and determine which ones may be keys\n",
    "            for j in range(1, num_labels_wh):\n",
    "                area = stats_wh[j, cv2.CC_STAT_AREA]\n",
    "                # !!! - min white pixel area\n",
    "                if (20 < area < np.inf): #filtering out relavent detections (the ones big enough to be keys)\n",
    "\n",
    "                    if j > 1:\n",
    "                        ## We've added another label\n",
    "                        num_labels +=1 \n",
    "                        i +=1\n",
    "\n",
    "                    #Within labels, we have a matrix that is the same size of the image that holds our split component\n",
    "                    #First, cut out the original \"fat\" label - i.e. two or more keys are coupled together\n",
    "                    coupled_keys_mask = labels != i\n",
    "                    labels = labels * coupled_keys_mask\n",
    "\n",
    "                    #Next, increment each label above the cut one up to accomodate the new label\n",
    "                    higher_mask = labels > i\n",
    "                    labels = labels + higher_mask\n",
    "\n",
    "                    #Then append our segregated key\n",
    "                    new_mask = labels_wh == j\n",
    "                    new_labels = labels_wh * new_mask\n",
    "                    new_labels = i * new_labels\n",
    "                    labels = labels + new_labels\n",
    "\n",
    "                    ##Remove the original index for the stats and then add the new one\n",
    "                    if i < len(stats):\n",
    "                        stats = np.delete(stats,i,0)\n",
    "                        stats = np.insert(stats,i,stats_wh[j],0)\n",
    "                    elif j == 1:\n",
    "                        stats = stats[:-1,:]\n",
    "                        stats = np.concatenate((stats,stats_wh[j][None,:]),0)\n",
    "                    else:\n",
    "                        stats = np.concatenate((stats,stats_wh[j][None,:]),0)\n",
    "\n",
    "                    ##Remove the original index for the centroids and then add the new one\n",
    "                    if i < len(centroids):\n",
    "                        centroids = np.delete(centroids,i,0)\n",
    "                        centroids = np.insert(centroids,i,centroids_wh[j],0)\n",
    "                    elif j==1:\n",
    "                        centroids = centroids[:-1,:]\n",
    "                        centroids = np.concatenate((centroids,centroids_wh[j][None,:]),0)  \n",
    "                    else:\n",
    "                        centroids = np.concatenate((centroids,centroids_wh[j][None,:]),0)  \n",
    "                        \n",
    "\n",
    "                        \n",
    "                    #Plot immediately so indexing doesn't get messed up\n",
    "                    # !!! - +20 pixels\n",
    "                    [x,y,w,h,area] = getConnectedComponentRectangle(stats[i,:])\n",
    "                    y += 20 # We cropped out the first 20 pixels\n",
    "                    \n",
    "                    if w >= black_width * 0.5:\n",
    "                        keys_timed_update = timeNotes(centroids[i], 20, h, keyboard_y_coords[1]-50, keyboard_array, \n",
    "                                                      keys_timed_update, elapsed, output_img,\n",
    "                                                      font = font, font_scale = 0.5, font_color = (128,0,128))\n",
    "\n",
    "\n",
    "                #Detect the next set of keys\n",
    "                black_tmp = threshMask.copy()\n",
    "                black_tmp[black_tmp>T] = 0        \n",
    "                k = 5\n",
    "                blurred_black_notes = cv2.GaussianBlur(black_tmp, (k,k), 0)\n",
    "\n",
    "                #Using standard threshold to create contrast between white/black keys\n",
    "                black_notes = threshold(blurred_black_notes, thresh_type = cv2.THRESH_BINARY)\n",
    "\n",
    "                #Detect the second set of keys\n",
    "                [num_labels_bl, labels_bl, stats_bl, centroids_bl] = connectedComponents(black_notes)\n",
    "                \n",
    "\n",
    "                #Loop through components and determine which ones may be keys\n",
    "                for k in range(1, num_labels_bl):\n",
    "                    area = stats_bl[k, cv2.CC_STAT_AREA]\n",
    "                    \n",
    "                    # !!! - min area\n",
    "                    if (20 < area < np.inf): #filtering out relavent detections (the ones big enough to be keys)\n",
    "\n",
    "                        if k > 1:\n",
    "                            ## We've added another label\n",
    "                            num_labels +=1 \n",
    "                            i+=1\n",
    "\n",
    "                        #For the second set of keys WE DON'T NEED TO CUT anything\n",
    "        #                 coupled_keys_mask = labels != i\n",
    "        #                 labels = labels * coupled_keys_mask\n",
    "\n",
    "                        #Next, increment each label above the cut one up to accomodate the new label\n",
    "                        higher_mask = labels > i + 1\n",
    "                        labels = labels + higher_mask\n",
    "\n",
    "                        #Then append our segregated key\n",
    "                        new_mask = labels_bl == k\n",
    "                        new_labels = labels_bl * new_mask\n",
    "                        new_labels = (i + 1) * new_labels\n",
    "                        labels = labels + new_labels\n",
    "\n",
    "                        ##Add\n",
    "                        if i < len(stats):\n",
    "                            stats = np.insert(stats,(i+1),stats_bl[k],0)                       \n",
    "                        else:\n",
    "                            stats = np.concatenate((stats,stats_bl[k][None,:]),0)\n",
    "                        \n",
    "\n",
    "                        ##Add\n",
    "                        if i < len(centroids):\n",
    "                            centroids = np.insert(centroids,(i+1),centroids_bl[k],0)\n",
    "                        else:\n",
    "                            centroids = np.concatenate((centroids,centroids_bl[k][None,:]),0)\n",
    "\n",
    "                        #Plot immediately so indexing doesn't get messed up\n",
    "                        # !!! - +20 pixels\n",
    "                        [x,y,w,h,area] = getConnectedComponentRectangle(stats[i+1,:])\n",
    "                        y += 20 # We cropped out the first 20 pixels\n",
    "\n",
    "                        \n",
    "                        # !!! - minimum black width\n",
    "                        if w >= black_width * 0.5:\n",
    "                            keys_timed_update = timeNotes(centroids[i+1], 20, h, keyboard_y_coords[1]-50, keyboard_array, \n",
    "                                                      keys_timed_update, elapsed, output_img,\n",
    "                                                      font = font, font_scale = 0.5, font_color = (0,0,255))\n",
    "\n",
    "        else:\n",
    "            # !!! - +20 pixels\n",
    "            [x,y,w,h,area] = getConnectedComponentRectangle(stats[i,:])\n",
    "            y += 20 # We cropped out the first 20 pixels\n",
    "            \n",
    "            \n",
    "            if (20 < area < np.inf) and w >= black_width * 0.5: #filtering out relavent detections (the ones big enough to be black keys)\n",
    "                keys_timed_update = timeNotes(centroids[i], 20, h, keyboard_y_coords[1]-50, keyboard_array, \n",
    "                                                      keys_timed_update, elapsed, output_img,\n",
    "                                                      font = font, font_scale = 0.33, font_color = (255,255,255))\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    \n",
    "    #Show the frame + drawn rectangle\n",
    "    cv2.imshow(\"Video\", output_img)\n",
    "\n",
    "    #Can break early by pressing \"q\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"p\"):\n",
    "        cv2.waitKey(-1) #wait until any key is pressed\n",
    "\n",
    "# print(keys_timed_update)    \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A0'],\n",
       " ['A#0'],\n",
       " ['B0'],\n",
       " ['C0'],\n",
       " ['C#0'],\n",
       " ['D0'],\n",
       " ['D#0'],\n",
       " ['E0'],\n",
       " ['F0'],\n",
       " ['F#0', [0.6333333333333333], [0.6666666666666666], [3.2333333333333334]],\n",
       " ['G0'],\n",
       " ['G#0', [15.5]],\n",
       " ['A1', [13.066666666666666], [13.1], [15.466666666666667]],\n",
       " ['A#1'],\n",
       " ['B1'],\n",
       " ['C1', [10.533333333333333], [10.566666666666666], [11.766666666666667]],\n",
       " ['C#1',\n",
       "  [0.6333333333333333],\n",
       "  [8.133333333333333],\n",
       "  [9.333333333333334],\n",
       "  [11.766666666666667],\n",
       "  [13.033333333333333]],\n",
       " ['D1'],\n",
       " ['D#1',\n",
       "  [3.2666666666666666],\n",
       "  [6.866666666666666],\n",
       "  [9.366666666666667],\n",
       "  [10.533333333333333]],\n",
       " ['E1', [6.9], [8.1]],\n",
       " ['F1'],\n",
       " ['F#1', [0.6666666666666666], [3.2333333333333334]],\n",
       " ['G1'],\n",
       " ['G#1', [15.5]],\n",
       " ['A2', [13.066666666666666], [13.1], [15.466666666666667]],\n",
       " ['A#2'],\n",
       " ['B2'],\n",
       " ['C2', [10.533333333333333], [10.566666666666666], [11.766666666666667]],\n",
       " ['C#2',\n",
       "  [0.6333333333333333],\n",
       "  [8.133333333333333],\n",
       "  [9.333333333333334],\n",
       "  [11.8],\n",
       "  [13.033333333333333]],\n",
       " ['D2'],\n",
       " ['D#2',\n",
       "  [3.2666666666666666],\n",
       "  [6.866666666666666],\n",
       "  [9.366666666666667],\n",
       "  [10.533333333333333]],\n",
       " ['E2', [8.1]],\n",
       " ['F2'],\n",
       " ['F#2',\n",
       "  [13.066666666666666],\n",
       "  [13.1],\n",
       "  [13.466666666666667],\n",
       "  [14.266666666666667],\n",
       "  [14.633333333333333]],\n",
       " ['G2'],\n",
       " ['G#2',\n",
       "  [10.566666666666666],\n",
       "  [10.933333333333334],\n",
       "  [11.766666666666667],\n",
       "  [12.166666666666666],\n",
       "  [15.5]],\n",
       " ['A3', [8.1], [8.5], [9.333333333333334], [9.733333333333333]],\n",
       " ['A#3'],\n",
       " ['B3',\n",
       "  [3.2333333333333334],\n",
       "  [3.6666666666666665],\n",
       "  [4.466666666666667],\n",
       "  [4.833333333333333],\n",
       "  [4.866666666666666],\n",
       "  [5.633333333333334],\n",
       "  [6.033333333333333],\n",
       "  [7.266666666666667]],\n",
       " ['C3'],\n",
       " ['C#3',\n",
       "  [0.6666666666666666],\n",
       "  [1.0666666666666667],\n",
       "  [1.9666666666666666],\n",
       "  [2.3333333333333335],\n",
       "  [12.2],\n",
       "  [12.566666666666666],\n",
       "  [12.6],\n",
       "  [13.5],\n",
       "  [13.833333333333334],\n",
       "  [13.866666666666667],\n",
       "  [14.666666666666666],\n",
       "  [15.033333333333333]],\n",
       " ['D3'],\n",
       " ['D#3',\n",
       "  [9.733333333333333],\n",
       "  [9.766666666666667],\n",
       "  [10.1],\n",
       "  [10.133333333333333],\n",
       "  [10.966666666666667],\n",
       "  [11.333333333333334],\n",
       "  [13.866666666666667],\n",
       "  [13.9],\n",
       "  [14.233333333333333],\n",
       "  [15.066666666666666],\n",
       "  [15.466666666666667]],\n",
       " ['E3',\n",
       "  [7.266666666666667],\n",
       "  [7.633333333333334],\n",
       "  [8.533333333333333],\n",
       "  [8.9],\n",
       "  [12.6],\n",
       "  [13.033333333333333]],\n",
       " ['F3', [0.13333333333333333], [0.16666666666666666]],\n",
       " ['F#3',\n",
       "  [1.1],\n",
       "  [1.5],\n",
       "  [2.3333333333333335],\n",
       "  [2.3666666666666667],\n",
       "  [2.4],\n",
       "  [2.7333333333333334],\n",
       "  [3.6666666666666665],\n",
       "  [3.7],\n",
       "  [4.033333333333333],\n",
       "  [4.866666666666666],\n",
       "  [5.233333333333333],\n",
       "  [6.066666666666666],\n",
       "  [6.433333333333334],\n",
       "  [10.133333333333333],\n",
       "  [10.166666666666666],\n",
       "  [10.533333333333333],\n",
       "  [11.366666666666667],\n",
       "  [11.766666666666667],\n",
       "  [13.066666666666666],\n",
       "  [13.1],\n",
       "  [15.466666666666667]],\n",
       " ['G3'],\n",
       " ['G#3',\n",
       "  [0.16666666666666666],\n",
       "  [0.6333333333333333],\n",
       "  [7.666666666666667],\n",
       "  [8.1],\n",
       "  [8.933333333333334],\n",
       "  [8.933333333333334],\n",
       "  [8.966666666666667],\n",
       "  [8.966666666666667],\n",
       "  [9.3],\n",
       "  [9.3],\n",
       "  [10.566666666666666],\n",
       "  [11.766666666666667],\n",
       "  [11.766666666666667],\n",
       "  [11.8],\n",
       "  [13.033333333333333],\n",
       "  [15.5]],\n",
       " ['A4',\n",
       "  [1.5333333333333334],\n",
       "  [1.9333333333333333],\n",
       "  [2.7333333333333334],\n",
       "  [3.2333333333333334],\n",
       "  [4.066666666666666],\n",
       "  [4.433333333333334],\n",
       "  [5.266666666666667],\n",
       "  [5.633333333333334],\n",
       "  [6.433333333333334],\n",
       "  [6.866666666666666],\n",
       "  [8.1],\n",
       "  [9.3],\n",
       "  [9.333333333333334],\n",
       "  [9.333333333333334],\n",
       "  [10.533333333333333]],\n",
       " ['A#4'],\n",
       " ['B4', [3.2333333333333334], [6.866666666666666], [6.866666666666666], [8.1]],\n",
       " ['C4'],\n",
       " ['C#4', [0.6333333333333333], [0.6666666666666666], [3.2333333333333334]],\n",
       " ['D4'],\n",
       " ['D#4'],\n",
       " ['E4'],\n",
       " ['F4'],\n",
       " ['F#4'],\n",
       " ['G4'],\n",
       " ['G#4'],\n",
       " ['A5'],\n",
       " ['A#5'],\n",
       " ['B5'],\n",
       " ['C5'],\n",
       " ['C#5'],\n",
       " ['D5'],\n",
       " ['D#5'],\n",
       " ['E5'],\n",
       " ['F5'],\n",
       " ['F#5'],\n",
       " ['G5'],\n",
       " ['G#5'],\n",
       " ['A6'],\n",
       " ['A#6'],\n",
       " ['B6'],\n",
       " ['C6'],\n",
       " ['C#6'],\n",
       " ['D6'],\n",
       " ['D#6'],\n",
       " ['E6'],\n",
       " ['F6'],\n",
       " ['F#6'],\n",
       " ['G6'],\n",
       " ['G#6'],\n",
       " ['A7'],\n",
       " ['A#7'],\n",
       " ['B7'],\n",
       " ['C7']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_timed_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "\n",
    "for i in range (len(keys_timed_update)):\n",
    "    temp = []\n",
    "    temp.append(keys_timed_update[i][0])\n",
    "    if (len(keys_timed_update[i]) > 1):\n",
    "        for j in range(1,len(keys_timed_update[i])):\n",
    "            temp.append(keys_timed_update[i][j][0])\n",
    "\n",
    "    new_list.append(temp)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(new_list)\n",
    "df.to_csv('notes_info.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "env_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
