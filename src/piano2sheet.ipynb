{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics\n",
    "import mahotas       # Otsu thresholding\n",
    "import bisect        # Key insert point\n",
    "import imutils       # Crop and resize images\n",
    "import pandas as pd\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "import youtube_dl\n",
    "import os            # Folder paths\n",
    "import sys           # Exit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note class\n",
    "class Note: \n",
    "    def __init__(self, centroid_x, y_dot):\n",
    "        self.centroid_x = centroid_x\n",
    "        self.y_dot = y_dot\n",
    "\n",
    "# just  a function for printing images\n",
    "def display_img(title, img):\n",
    "    cv2.imshow(title, img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "      \n",
    "# function for getting next note\n",
    "def getNextNote(first_note):\n",
    "    if \"#\" in first_note: \n",
    "        octave = first_note[2]\n",
    "        if first_note[:2] == \"A#\":\n",
    "            return (\"C#\" + octave)\n",
    "        elif first_note[:2] == \"C#\":\n",
    "            return (\"D#\" + octave)\n",
    "        elif first_note[:2] == \"D#\":\n",
    "            return (\"F#\" + octave)\n",
    "        elif first_note[:2] == \"F#\":\n",
    "            return (\"G#\" + octave)\n",
    "        elif first_note[:2] == \"G#\":\n",
    "            next_octave = int(octave) + 1\n",
    "            return (\"A#\" + str(next_octave))\n",
    "    \n",
    "    else: \n",
    "        octave = first_note[1]\n",
    "        if first_note[0] == \"A\":\n",
    "            return (\"B\" + octave)\n",
    "        elif first_note[0] == \"B\":\n",
    "            return (\"C\" + octave)\n",
    "        elif first_note[0] == \"C\":\n",
    "            return (\"D\" + octave)\n",
    "        elif first_note[0] == \"D\":\n",
    "            return (\"E\" + octave)\n",
    "        elif first_note[0] == \"E\":\n",
    "            return (\"F\" + octave)\n",
    "        elif first_note[0] == \"F\":\n",
    "            return (\"G\" + octave)\n",
    "        elif first_note[0] == \"G\":\n",
    "            next_octave = int(octave) + 1\n",
    "            return (\"A\" + str(next_octave))\n",
    "\n",
    "# Function for Gaussian Blurring\n",
    "def gaussianBlurring(gray_img, blur_sq, std_dev = 0):\n",
    "    return cv2.GaussianBlur(gray_img, (blur_sq, blur_sq), std_dev)\n",
    "\n",
    "# Function for Canny Edge Detection\n",
    "def cannyDetection(blurred_img, th1, th2, apertureSize = 3):\n",
    "    return cv2.Canny(blurred_img, th1, th2, apertureSize)\n",
    "\n",
    "# Function to return the top and bottom of the keyboard using HoughLines\n",
    "def keyboardYCoords(edged_img, rho = 1, theta = np.pi/180, threshold = None):\n",
    "    \n",
    "    if threshold is None:\n",
    "        threshold = edged_img.shape[1]//2 # half the width\n",
    "    \n",
    "    lines = cv2.HoughLines(edged_img, rho, theta, threshold) \n",
    "    y_cord = [] #the y-value of the lines generated from hough transform\n",
    "\n",
    "    #iterating through lines\n",
    "    for line in lines: \n",
    "        rho_l, theta_l = line[0]\n",
    "        a = np.cos(theta_l)\n",
    "        b = np.sin(theta_l)\n",
    "        x0 = a * rho_l\n",
    "        y0 = b * rho_l\n",
    "        y_cord.append(y0) #appending to list\n",
    "\n",
    "    y_cord.sort(reverse=True)\n",
    "    return y_cord[0:2]\n",
    "\n",
    "# Function to threshold an image\n",
    "def theshold(gray_img, th1 = 90, th2 = 150, thresh_type = cv2.THRESH_BINARY_INV):\n",
    "    _, threshed_img = cv2.threshold(gray_img, th1, th2, thresh_type)\n",
    "    return threshed_img\n",
    "\n",
    "\n",
    "        \n",
    "# Function for doing connected components\n",
    "def connectedComponents(binarized_img, img, display_result):\n",
    "    connectivity = 1\n",
    "    output = cv2.connectedComponentsWithStats(binarized_img, connectivity, cv2.CV_32S)\n",
    "    num_labels = output[0]\n",
    "    labels = output[1]\n",
    "    stats = output[2]\n",
    "    centroids = output[3]\n",
    "\n",
    "    final_labels = []\n",
    "\n",
    "    output = img.copy()\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        x = stats[i, cv2.CC_STAT_LEFT]\n",
    "        y = stats[i, cv2.CC_STAT_TOP]\n",
    "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        (cX, cY) = centroids[i]\n",
    "        \n",
    "        if (100 < area < np.inf):\n",
    "            final_labels.append([i,cX])\n",
    "            \n",
    "            if (display_result):\n",
    "                cv2.rectangle(output, (x,y), (x+w, y+h), (255,0,0),1)\n",
    "                cv2.circle(output, (int(cX), int(cY)), 4, (255,255,0), -1)\n",
    "                componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "                cv2.imshow(\"Output\", output)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "    key_width = statistics.median(stats[:, cv2.CC_STAT_WIDTH])\n",
    "    cv2.destroyAllWindows()\n",
    "    return final_labels, key_width\n",
    "\n",
    "\n",
    "def displayCentroid(key_list, img):\n",
    "    y = img.shape[0]*3//4\n",
    "    for (note, centroid) in key_list: \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        line = cv2.line(img,(int(centroid),0),(int(centroid),900),(0,0,255),1)\n",
    "        text_label = cv2.putText(img, note, (int(centroid), y), font, 0.5, (0,255,0), 1)\n",
    "        cv2.imshow(\"Key Label\", img)\n",
    "        cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def key_pressed(key_list, key_index):\n",
    "    insertion_point = bisect.bisect_left(key_list[:,1].astype(float),key_index)\n",
    "    \n",
    "    #Insertion outside our index, means to insert it at the end (return the last key)\n",
    "    if insertion_point >= len(key_list):\n",
    "        insertion_point = len(key_list)-1\n",
    "#     print(insertion_point)\n",
    "#     print('You pressed the {} key.'.format(key_list[insertion_point,0]))\n",
    "\n",
    "    note = key_list[insertion_point,0]\n",
    "    index = insertion_point\n",
    "\n",
    "    return note, index\n",
    "\n",
    "\n",
    "\n",
    "# For downloading YouTube videos\n",
    "def my_hook(d):\n",
    "    if d['status'] == 'finished':\n",
    "        print('Download complete.')\n",
    "    elif d['status'] == 'error':\n",
    "        print('Error in downloading file - exiting program!')\n",
    "        sys.exit()\n",
    "        \n",
    "        \n",
    "# Function to download a YouTube video\n",
    "def downloadYouTube(videourl, path = './videos/video_to_process.%(ext)s', quiet = True):\n",
    "    \n",
    "    ydl_opts = {'outtmpl': path,\n",
    "               'quiet': quiet,\n",
    "               'progress_hooks': [my_hook]}\n",
    "    try:\n",
    "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([videourl])\n",
    "    except youtube_dl.utils.DownloadError:\n",
    "        print('Exiting program!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ask user for YouTube link\n",
    "- Download (?) video (or atleast a temporary copy)\n",
    "- Using the first few frames, detect the keyboard\n",
    "    - If 72 keys are not detected, try next few frames and repeat\n",
    "    - If they can't be detected at all, end program\n",
    "- Label black and white keys\n",
    "- Run algorithm, get array with start/end times for each note\n",
    "- Convert to .midi\n",
    "- Convert to sheet music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Incomplete YouTube ID BaWzKc. URL https://www.youtube.com/watch?v=BaWzKc looks truncated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting program!\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade youtube-dl\n",
    "\n",
    "\n",
    "#Need to ask user for a URL here\n",
    "downloadYouTube('https://www.youtube.com/watch?v=BaWzKc', quiet = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the downloaded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture('./videos/Nocturne Opus 9 No 2_Trim.mp4')\n",
    "\n",
    "# Could not access the file\n",
    "if not camera.isOpened():\n",
    "    print('Error in accessing file - exiting program!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through and attempt to detect 72 keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    #grabbed is a boolean than tells us if there is a valid frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "    if not grabbed:\n",
    "        break\n",
    "        \n",
    "    frame = imutils.resize(frame,width = 600)\n",
    "    \n",
    "    # Get the bottom-half of the frame (where the keyboard lies) and process from here\n",
    "    keys = frame[frame.shape[0]//2:,:]\n",
    "    gray_keys = cv2.cvtColor(keys, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Process\n",
    "    blurred = gaussianBlurring(gray_keys, blur_sq = 5)\n",
    "    edges = cannyDetection(blurred, th1 = 200, th2 = 200)\n",
    "\n",
    "    # Crop\n",
    "    crop_coordinates  = keyboardYCoords(edges)\n",
    "    cropped_keys      = keys[int(crop_coordinates[1])+20:int(crop_coordinates[0])]\n",
    "    cropped_gray_keys = gray_keys[int(crop_coordinates[1])+20:int(crop_coordinates[0])]\n",
    "    \n",
    "    # Labels keys\n",
    "    thresh_keys = theshold(cropped_gray_keys, th1 = 90, th2 = 150)\n",
    "    \n",
    "    # Black keys\n",
    "    final_labels_bl, key_width_bl = connectedComponents(thresh_keys, cropped_keys, False)\n",
    "    if len(final_labels_bl) == 36: \n",
    "        first_note = \"A#0\"\n",
    "        for i in range(36):\n",
    "            final_labels_bl[i][0] = first_note\n",
    "            first_note = getNextNote(first_note)\n",
    "            \n",
    "        final_labels_bl = sorted(final_labels_bl, key=lambda x: x[1])\n",
    "\n",
    "    # White keys\n",
    "    blurred_w = gaussianBlurring(cropped_gray_keys, blur_sq = 7)\n",
    "    T = mahotas.thresholding.otsu(blurred_w)*1.3\n",
    "    thresh_keys_w = cropped_gray_keys.copy()\n",
    "    thresh_keys_w[thresh_keys_w>T] = 255\n",
    "    thresh_keys_w[thresh_keys_w<T] = 0\n",
    "    final_labels_w, key_width_w = connectedComponents(thresh_keys_w, cropped_keys, False)\n",
    "        \n",
    "    if len(final_labels_w) == 52: \n",
    "        first_note = \"A0\"\n",
    "        for i in range(52):\n",
    "            final_labels_w[i][0] = first_note\n",
    "            first_note = getNextNote(first_note)\n",
    "            \n",
    "        final_labels_w = sorted(final_labels_w, key=lambda x: x[1])\n",
    "        \n",
    "    # Determine if they sum to 88 keys (36 black, 52 white) - if not, try next frame\n",
    "        if len(final_labels_bl) == 36 and len(final_labels_w) == 52:\n",
    "            break\n",
    "\n",
    "#     #Show the frame + drawn rectangle\n",
    "#     cv2.imshow(\"Face\", thresh_keys)\n",
    "\n",
    "    #Can break early by pressing \"q\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "# If at this point we've looped through everything and we don't have 72 keys\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if len(final_labels_bl) != 36 and len(final_labels_w) != 52:\n",
    "    print('Error in processing file - exiting program!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts on a 'Piano' class - initialized with an image.\n",
    "Methods:\n",
    "-Gray keyboard\n",
    "-Blur keyboard\n",
    "-Canny Keyboard, etc. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGNORE BELOW THIS LINE ##########################\n",
    "_______________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load image in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always start at the first frame - before ANY keys are clicked. This is because if a note is coloured on the keys themselves, our thresholding set-up doesn't work.\n",
    "\n",
    "**There is an issue when people have intros...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[174.0, 106.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reading in image\n",
    "keys = cv2.imread(\"images\\synthesia.png\")\n",
    "keys = keys[keys.shape[0]//2:,:]\n",
    "\n",
    "#grayscale\n",
    "gray_keys = cv2.cvtColor(keys, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "################################\n",
    "################# edge detection\n",
    "std_dev = 0\n",
    "k = 5\n",
    "t1 = 200\n",
    "t2 = 200\n",
    "blurred = cv2.GaussianBlur(gray_keys, (k,k), std_dev)\n",
    "edges = cv2.Canny(blurred, t1,t2, apertureSize = 3)\n",
    "\n",
    "################################\n",
    "################# hough transform \n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, 300) \n",
    "y_cord = [] #the y-value of the lines generated from hough transform\n",
    "\n",
    "#iterating through lines\n",
    "for line in lines: \n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    y_cord.append(y0) #appending to list\n",
    "\n",
    "print(y_cord)\n",
    "\n",
    "#Only want to two lines from hough transform that crops out image of piano\n",
    "if (len(y_cord) > 2):\n",
    "    y_cord.sort(reverse=True)\n",
    "    y_cord.pop()\n",
    "    \n",
    "    \n",
    "\n",
    "#crop gray\n",
    "cropped_keys      = keys[int(y_cord[1])+20:int(y_cord[0])]\n",
    "cropped_gray_keys = gray_keys[int(y_cord[1])+20:int(y_cord[0])]\n",
    "\n",
    "################################\n",
    "################# thresholding\n",
    "_, th1 = cv2.threshold(cropped_gray_keys, 90, 150, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "plt.imshow(edges)\n",
    "# plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAABMCAYAAACiaYmMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPh0lEQVR4nO3dfWxU9ZoH8O/ToaX0jZdbLKXlRWmhVKSlGqhesi7XsKnGiBsw3MawhBVZGyRo2BjZNZu7mv2Df3Cv7uZG96KbkJu9yKV4QaEuCtm4iiIUCgUESq2AlPaUl0pA2s7Ms3/MKTvtOZ3pmTnzVr+f5JfOPPP7nd8zD50zTzvTQVQVRERERDR8aYlOgIiIiCjVsIEiIiIicogNFBEREZFDbKCIiIiIHGIDRUREROQQGygiIiIih6JqoESkRkTOiEiLiLzqVlJEREREyUwi/RwoEfEAOAtgMYBLAL4BUKuqp9xLj4iIiCj5RPMbqPkAWlS1VVV7AfwRwBJ30iIiIiJKXqOiWFsE4GLQ9UsAFgyeJCJrAKwBgKysrAdv374d8qD5+fmYNm2aJX7z5k2cPXvWUYKZmZm4//77LXGv14umpibbNenp6Zg7d64lrqpobGx0tD8AVFVVQUQs8aamJni93gGxGTNmYNy4cZa5ly5dQkdHhyU+ceJETJ061RLv7u5GS0uLozyzsrIwe/ZsS7yvrw/Hjx+3XZORkYEHHnjAEm9sbEQkv9l88MEHLbFTp07hp59+ssRLSkowduxYS/zixYvo7Oy0xO+55x5MmTLFEr9x4wbOnz/vKM/s7GyUlZVZ4r29vThx4oTtmtGjR2POnDmWuJu1OnnyJO7cuWOJl5aWIi8vzxK/cOECDMOwxAsKClBcXGyJX79+Ha2trY7yzMnJwaxZsyzxnp4eNDc3264Z6nF75MgRR3sDgIigqqrKEm9ubkZPT48lPnPmTOTm5lribW1tuHr1qiVeWFiIyZMnD4jdunUL3377reNcc3NzMXPmzAExv9+Po0ePDrkmHrU6ceIEent7LfFZs2YhJyfHEv/uu+9w7do1S3zy5MkoLCwcEIu0Vnl5eSgtLR0Q8/l8OHbs2JBrxowZg/Lycks8klqlpaVh3rx5lvjx48fR19dniZeVlSE7O9sSb21txfXr1y3xoqIiTJo0aUAskudAABg7dixKSkoGxEI9BwL257hInwOHqpXdcyAAzJ49G1lZWZZ4S0sLuru7LfHi4mIUFBQMiP344484d+6c41wHq6ioQFNTU5eqTrSdoKoRDQDLAPw+6PoKAP8Wak1FRYUCCDlWr16tdj799NOwawePOXPm2B6rs7NzyDVFRUW2a+7cueN4fwDa19dne7z8/HzL3B07dtjO3bBhg+2x6+rqbOfv2bPHcZ5VVVW2x7p8+fKQa6ZOnWq7JjMz0/H+IqJer9dyrLlz59rO37Vrl+3e69ats53/8ssv287/8MMPHedaXV1te6zvv/9+yDUzZsywXZORkeF4f4/Ho36/33Ks8vJy2/kNDQ22e7/wwgu281955RXb+R988IHjXBcuXGh7rPPnzw+5pqyszDLf7/erx+NxvH96errt/iUlJbbz9+/fbzt/1apVtvNfe+01y9xDhw45zhOAPvbYY5Zj3bx5M+Qau3Ocz+fTtLQ0x/uPHj3a9r5Pnz7ddv7nn39uO7+2ttZ2/htvvGGZ++WXX0ZUq5qaGsuxuru7Q66prKy0rPF6vSoijvfPysqyve/FxcW287/66ivb+c8884zt/E2bNlnmHjhwIKJaLVmyxHKsq1evhlxjd47r7e2NaP/c3Fzb+z5p0iTb+Y2NjbbzlyxZYjt/8+bNlrn79u2LKNfBo6urSwEc1iF6mmhewvsBQPCP9MVmjIiIiGhEi6aB+gZAqYjcKyIZAH4NYJc7aRERERElr4jfA6WqXhF5EcAnADwA3lPVk65lRkRERJSkonkTOVR1D4A9LuVCRERElBL4SeREREREDrGBIiIiInKIDRQRERGRQ2ygiIiIiBxiA0VERETkEBsoIiIiIofYQBERERE5xAYqAfx+f6JTICIioiiwgUqABQsWoKurK9FpEBERUYTYQCWAqiY6BSIiIooCG6hhqq+vT3QKlMT8fj927Rq5/5f2jRs38MUXXyQ6DSKipMEGapief/75RKdASUxV0dramug0Yqanpwft7e2JToOIKGmwgRqmLVu2JDoFSmIejwcvvfRSotOImYKCAixbtsyVY/X19eHFF1905VhERIkStoESkSkickBETonISRFZb8Z/IyI/iMgxczwR+3QT5+mnn050CkQjgtfrxd69exOdBhFRVIbzGygvgA2qWg6gGsBaESk3b3tTVSvNsceNhFT17pus/X7/gBEJu7XhjtW/v6reXe/z+SLa3+fzwe/3Dzjmvn37MGHCBNt9B+cb6r4PrlX/10hztdsr3LHsahWp/vXBxwy1r92/61Br3Py+6j/W4L0i+b6KlN331VCGegyEqtXgtW4+BjMyMnDo0KGQa5KlVuH2HqpWkRq8fsyYMTh48GDINYNrFenjP3j/SB+D4Wo7eJ9Ic7V7DA7nWLGu1VD3363HYCSGel4Jt6Z/RPtv1b9ftI/BeNTKseBCDWcA+DOAxQB+A+DvnaytqKhQAGHH66+/roZh6IwZM1RE7o7hrB08+te+8847ahiGXrlyRT0eT8g11dXVahiGrl271rX9n3zySb1165Y+++yzQx6rf25GRoZ2dnbqxx9/HHbfTZs2qWEYOm3aND1z5owrub7//vtqGIa2t7drWlpayDULFy5UwzB09erVUe0dvP/SpUvVMAx96qmnws5ta2tTn8+nO3fuDLv35s2b1TAMLSoqivrftba2VtetW6dbt25Vr9erly9fDlurRYsWqWEYunLlStdqtXz5cjUMQx9//PGwcy9cuKCGYej27dvD7v3222+rYRg6adIk1x4D27ZtU5/Ppzk5OWGPVVNTo4ZhaG1trWu1WrFihRqGoYsXLw45Ny0tTS9evKgHDx4c1t7955b8/HzXcq2vr1fDMDQzMzPs8ZYuXaq3b9/WZcuWubb/qlWr1DAMffTRR8PWqr29Xb1erxqGoRs3bgw5v//cMn78+Khzraur0xUrVuju3bu1s7NTMzIywq4JPre4Vau6ujo1DEMfeeSRkHM9Ho9euXJFDcPQd999N+TeIqJbt25VwzA0Ly/PtVz37t2rHR0dmp6eHnbN8uXLdf369VE//oP3X7dunRqGofPnzw85d9SoUdrR0aENDQ1h9xYRbWho0GvXrml2dnbUuQaPrq4uBXB4yH7IYfM0HcAFAHkINFBtAI4DeA/A+CHWrAFwGMDh4uJiV+5Uqo5Vq1ZpTU1NwvMYSSM9PV13796d0By2b9+uWVlZCa9FKoydO3dqZmZmwvMYSWPRokVaV1eXsP1zcnJ027ZtCa8Dx893vPXWWzplyhTXjxuugZLhfiaRiOQA+B8A/6Kq9SJSAKDL3OgNAIWq+rehjlFZWalNTU3D2o+IiIgoUbq6upCfn39EVR+yu31Yf4UnIukAdgD4g6rWA4CqdqiqT1X9AP4DwHy3kiYiIiJKZsP5KzwBsAXAaVXdHBQvDJr21wCa3U+PiIiIKPmMGsacXwJYAeCEiBwzY/8AoFZEKhF4Ca8NwN/FID8iIiKipBO2gVLV/wUgNje58rEFRERERKmGn0RORERE5BAbKCIiIiKH2EAREREROcQGioiIiMghNlBEREREDrGBIiIiInKIDRQRERGRQ2ygiIiIiBxiA0VERETkEBsoIiIiIofYQBERERE5xAaKiIiIyCE2UEREREQOsYEiIiIickhUNX6bidwEcCZuG/785APoSnQSIxRrGzusbeywtrHD2sZWstR3mqpOtLthVJwTOaOqD8V5z58NETnM+sYGaxs7rG3ssLaxw9rGVirUly/hERERETnEBoqIiIjIoXg3UO/Geb+fG9Y3dljb2GFtY4e1jR3WNraSvr5xfRM5ERER0UjAl/CIiIiIHGIDRURERORQ3BooEakRkTMi0iIir8Zr35FCRN4TkU4RaQ6KTRCRfSJyzvw63oyLiLxl1vq4iFQlLvPkJyJTROSAiJwSkZMist6Ms75REpFMETkkIk1mbf/ZjN8rIl+bNdwmIhlmfLR5vcW8fXpC70AKEBGPiBwVkY/M66ytS0SkTUROiMgxETlsxnhecIGIjBORP4nItyJyWkQeTrXaxqWBEhEPgH8H8DiAcgC1IlIej71HkP8EUDMo9iqAz1S1FMBn5nUgUOdSc6wB8Ls45ZiqvAA2qGo5gGoAa83vT9Y3ej0AfqWqFQAqAdSISDWATQDeVNUSANcBPGfOfw7AdTP+pjmPQlsP4HTQddbWXYtUtTLoM4l4XnDHbwE0qGoZgAoEvodTq7aqGvMB4GEAnwRd3whgYzz2HkkDwHQAzUHXzwAoNC8XIvBBpQDwDoBau3kcw6rznwEsZn1dr2sWgEYACxD4hOFRZvzu+QHAJwAeNi+PMudJonNP1gGgGIEnml8B+AiAsLau1rcNQP6gGM8L0dd1LIDvBn//pVpt4/USXhGAi0HXL5kxik6Bqrabl68AKDAvs94RMl/WmAfga7C+rjBfYjoGoBPAPgDnAdxQVa85Jbh+d2tr3t4N4BdxTTi1/CuAVwD4zeu/AGvrJgXw3yJyRETWmDGeF6J3LwADwPvmy8+/F5FspFht+SbyEUIDbTk/kyIKIpIDYAeAl1T1x+DbWN/IqapPVSsR+G3JfABlic1oZBCRJwF0quqRROcygi1U1SoEXkJaKyJ/EXwjzwsRGwWgCsDvVHUegFv4/5frAKRGbePVQP0AYErQ9WIzRtHpEJFCADC/dppx1tshEUlHoHn6g6rWm2HW10WqegPAAQReVhonIv3/F2dw/e7W1rx9LICr8c00ZfwSwFMi0gbgjwi8jPdbsLauUdUfzK+dAHYi8AMAzwvRuwTgkqp+bV7/EwINVUrVNl4N1DcASs2/DskA8GsAu+K090i2C8BK8/JKBN670x//G/MvF6oBdAf9WpQGEREBsAXAaVXdHHQT6xslEZkoIuPMy2MQeG/ZaQQaqWXmtMG17a/5MgD7zZ9EaRBV3aiqxao6HYFz6n5VfRasrStEJFtEcvsvA/grAM3geSFqqnoFwEURmWWGHgNwCqlW2zi+aewJAGcReP/DPyb6zV+pNgD8F4B2AH0IdO/PIfD+hc8AnAPwKYAJ5lxB4K8ezwM4AeChROefzAPAQgR+VXwcwDFzPMH6ulLbuQCOmrVtBvBPZvw+AIcAtADYDmC0Gc80r7eYt9+X6PuQCgPAXwL4iLV1tab3AWgyx8n+5y2eF1yrbyWAw+a54UMA41OttvyvXIiIiIgc4pvIiYiIiBxiA0VERETkEBsoIiIiIofYQBERERE5xAaKiIiIyCE2UEREREQOsYEiIiIicuj/AEvf7f1UNGFcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(th1, cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Label Black Keys\n",
    "We don't need to do distance math anymore. If we detect 36 black keys, we know that the first black key is A#."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*final_labels* is the 36 integer indices that tell us if the returned centroids are black keys. \n",
    "\n",
    "For example, if centroids returns 39 possible connected components, final_label is the list of 36 indices that we consider are black keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get the average width of a black key\n",
    "### Also get all balck key info (centroid etc)\n",
    "This will be used to determine the discrete range of each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################\n",
    "################# Connected Components (for black keys)\n",
    "#SWITCH TRUE TO FALSE IF YOU DONT WANT TO SHOW OUTPUT\n",
    "final_labels_bl, key_width_bl = connectedComponents(th1, cropped_keys, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################################\n",
    "################# Labelling (for black keys)\n",
    "if len(final_labels_bl) == 36: \n",
    "    first_note = \"A#0\"\n",
    "    for i in range(36):\n",
    "        final_labels_bl[i][0] = first_note\n",
    "        first_note = getNextNote(first_note)\n",
    "\n",
    "final_labels_bl = sorted(final_labels_bl, key=lambda x: x[1])\n",
    "\n",
    "#just displaying to test\n",
    "# displayCentroid(final_labels_bl, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Label White Keys\n",
    "Testing white keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "################# Connected Components (for white keys)\n",
    "k = 7\n",
    "blurred = cv2.GaussianBlur(cropped_gray_keys, (k,k), 0)\n",
    "T = mahotas.thresholding.otsu(blurred)*1.3\n",
    "th2 = cropped_gray_keys.copy()\n",
    "th2[th2>T] = 255\n",
    "th2[th2<T] = 0\n",
    "final_labels_w, key_width_w = connectedComponents(th2, cropped_keys, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "################# Labelling (for white keys)\n",
    "if len(final_labels_w) == 52: \n",
    "    first_note = \"A0\"\n",
    "    for i in range(52):\n",
    "        final_labels_w[i][0] = first_note\n",
    "        first_note = getNextNote(first_note)\n",
    "\n",
    "final_labels_w = sorted(final_labels_w, key=lambda x: x[1])\n",
    "\n",
    "#just displaying to test\n",
    "# displayCentroid(final_labels_w, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Assign Ranges\n",
    "Order both the white and black keys together. \n",
    "\n",
    "For the range x:0 -> end, we assign a specify range to each key. For example, A: 0 - 10, A#: 10 - 15.\n",
    "\n",
    "Our assumption is that the centroid of the key played will land in a discrete range with no overlap/ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "################# Assign ranges\n",
    "full_key_list = final_labels_bl + final_labels_w\n",
    "full_key_list = sorted(full_key_list, key=lambda x: x[1].astype(float))\n",
    "# for ls in full_key_list: \n",
    "#     ls = ls.reverse()\n",
    "full_key_list = np.array(full_key_list)\n",
    "# print(full_key_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below maps the actual range for each discrete key.\n",
    "\n",
    "We know that black keys are skinnier than white keys, and we took the median width of the black keys above. For each black key, it's range is ***centroid - black_key_width/2 < x < centroid + black_key_width/2***.\n",
    "\n",
    "For white keys adjacent to black keys, the above axiom provides one of the bounds.\n",
    "\n",
    "For white keys adjacent to white keys, we simply take the mid-way point between their centroids as one of the bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_list = np.empty([len(full_key_list), 2], dtype='object')\n",
    "\n",
    "for i in range(0,len(full_key_list)-1):\n",
    "    if len(full_key_list[i,0])==1 and len(full_key_list[i+1,0])>1: # White adjacent to black\n",
    "        test_list[i,1] = full_key_list[i+1,1].astype(float) - key_width_bl/2\n",
    "    elif len(full_key_list[i,0])>1: # Black key\n",
    "        test_list[i,1] = full_key_list[i,1].astype(float) + key_width_bl/2\n",
    "    else: # White key adjacent to white key\n",
    "        test_list[i,1] = (full_key_list[i,1].astype(float)+full_key_list[i+1,1].astype(float))/2\n",
    "    \n",
    "    # No change to the actual note (only the distances, above)\n",
    "    test_list[i,0] = full_key_list[i,0]\n",
    "\n",
    "#For the last key, just take it to infinity\n",
    "test_list[-1,1] = np.inf\n",
    "test_list[-1,0] = full_key_list[-1,0]\n",
    "\n",
    "full_key_list = test_list\n",
    "#print(full_key_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below **inserts** any given value between our established key ranges. It returns an index where the given value *would* be inserted, which gives us our corresponding key pressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note, index = key_pressed(full_key_list, 999)\n",
    "# print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing with Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample piano image from youtube\n",
    "img_notes = cv2.imread(\"images/IMG_very_close_notes.png\")\n",
    "\n",
    "#converting to gray\n",
    "gray_notes = cv2.cvtColor(img_notes, cv2.COLOR_BGR2GRAY)\n",
    "img_notes_rgb = cv2.cvtColor(img_notes, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_notes_rgb)\n",
    "# plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*y_cord[1]* is the position of the top of the keyboard. We calculated this using **half** the original image, so we need to add this back in.\n",
    "\n",
    "# I added it back paps =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cropped\n",
    "top_keys_index = y_cord[1] + img_notes.shape[0]//2\n",
    "crop_img_notes = img_notes[20:(int(top_keys_index)-30)] #Crop the top 20 pixels and bottom 30\n",
    "\n",
    "plt.imshow(crop_img_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_img_notes_gray = cv2.cvtColor(crop_img_notes, cv2.COLOR_BGR2GRAY)\n",
    "# # # k = 3\n",
    "# # # blurred = cv2.GaussianBlur(crop_img_notes_gray, (k,k), 0)\n",
    "\n",
    "# # #Using standard threshold to create contrast between white/black keys\n",
    "# # _, th_notes = cv2.threshold(blurred, 90, 150, cv2.THRESH_BINARY)\n",
    "\n",
    "# _, th_notes = cv2.threshold(crop_img_notes_gray, 90, 150, cv2.THRESH_BINARY)\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(th_notes, cmap = \"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #####################################################################################\n",
    "# ####### using connected component detection algorithm to separate all the black notes\n",
    "# connectivity = 1\n",
    "# output = cv2.connectedComponentsWithStats(th_notes, connectivity, cv2.CV_32S)\n",
    "# num_labels = output[0]\n",
    "# labels = output[1]\n",
    "# stats = output[2]\n",
    "# centroids = output[3]\n",
    "\n",
    "# final_labels = []\n",
    "# note_list = [] #creating a list of all the relavent notes. \n",
    "\n",
    "\n",
    "# output = img_notes_rgb.copy()\n",
    "# font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# #For loop only used for displaying \n",
    "# for i in range(1, num_labels):\n",
    "#     x = stats[i, cv2.CC_STAT_LEFT]\n",
    "#     y = stats[i, cv2.CC_STAT_TOP] + 20 # We cropped out the first 20 pixels\n",
    "#     w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "#     h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "#     area = stats[i, cv2.CC_STAT_AREA]\n",
    "#     (cX, cY) = centroids[i]\n",
    "#     cY = cY + 20 # We cropped out the first 20 pixels\n",
    "#     if (20 < area < np.inf): #filtering out relavent detections (the ones big enough to be black keys)\n",
    "#         final_labels.append(i)\n",
    "#         cv2.rectangle(output, (x,y), (x+w, y+h), (255,0,0),1)\n",
    "#         dist_to_edge = h/2 #getting the distance from centroid to bottom edge for better detection later on\n",
    "#         cv2.circle(output, (int(cX), int(cY+dist_to_edge)), 1, (0,122,255), 3)\n",
    "#         componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "        \n",
    "#         note = Note(cX, cY+dist_to_edge) #creating note object and adding to list\n",
    "#         note_list.append(note)\n",
    "        \n",
    "#         note_played, _ = key_pressed(full_key_list, note.centroid_x)\n",
    "#         cv2.putText(output, note_played, (int(note.centroid_x), int(note.y_dot)), font, 0.5, (0,255,0), 1)\n",
    "\n",
    "# #         display_img(\"Output\", output)\n",
    "# #         display_img(\"Connected Component\", componentMask)\n",
    "# #         cv2.waitKey(0)\n",
    "\n",
    "# # print(final_labels)\n",
    "# # cv2.destroyAllWindows()\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(output)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture('videos/Nocturne Opus 9 No 2_trim.mp4')\n",
    "\n",
    "frames = camera.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "seconds_per_frame = fps/frames\n",
    "counter = 0\n",
    "\n",
    "notes_pressed = []\n",
    "\n",
    "keys_timed = []\n",
    "for x in full_key_list:\n",
    "    keys_timed.append([x[0]])\n",
    "\n",
    "\n",
    "keys_timed_update = []\n",
    "for x in full_key_list:\n",
    "    keys_timed_update.append([x[0]])\n",
    "\n",
    "    \n",
    "testing_screen = []\n",
    "testing_mask = []\n",
    "\n",
    "while (camera.isOpened()):\n",
    "    #print(counter)\n",
    "    #print('-'*100)\n",
    "    \n",
    "    #grabbed is a boolean than tells us if there is a valid frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "\n",
    "    frame_number = camera.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    elapsed = frame_number/fps\n",
    "\n",
    "    \n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    counter += seconds_per_frame\n",
    "        \n",
    "         \n",
    "    frame = imutils.resize(frame,width = keys.shape[1]) #resize or else it won't work\n",
    "    #print(frame.shape)\n",
    "    \n",
    "    crop_frame = frame[20:int(top_keys_index)-50] #Crop the top 20 pixels and bottom 10\n",
    "    \n",
    "    # threshold the cropped and grayed image\n",
    "    crop_frame_gray = cv2.cvtColor(crop_frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, th_crop_frame = cv2.threshold(crop_frame_gray, 90, 150, cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "    #We have a thresholded image for use to use ConnectedComponents on\n",
    "    #####################################################################################\n",
    "    ####### using connected component detection algorithm to separate all the black notes\n",
    "    connectivity = 8\n",
    "    output = cv2.connectedComponentsWithStats(th_crop_frame, connectivity, cv2.CV_32S)\n",
    "    num_labels = output[0]\n",
    "    labels = output[1]\n",
    "    stats = output[2]\n",
    "    centroids = output[3]\n",
    "\n",
    "    indices_to_pop = []\n",
    "\n",
    "\n",
    "    output_img = frame.copy()\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    \n",
    "#     print(\"-\"*50)\n",
    "#     print(\"new frame\")\n",
    "    i=1\n",
    "    #Loop through all the connected components\n",
    "    while i < len(stats):\n",
    "\n",
    "        curr_connected_w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "\n",
    "        #Determine if the WIDTH is much bigger than the width of a white key and less than 4x? (So we don't get extraneous video text, etc.)\n",
    "        if curr_connected_w > key_width_w*1.25 and curr_connected_w < key_width_w*4:\n",
    "            \n",
    "\n",
    "\n",
    "            #Threshold just the large component of interest\n",
    "            componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "            threshMask = cv2.bitwise_and(crop_frame_gray, crop_frame_gray, mask = componentMask) #Replace this with video frame\n",
    "\n",
    "#             print(\"We are here.\")\n",
    "#             testing_screen.append(frame.copy())\n",
    "#             testing_mask.append(threshMask.copy())\n",
    "            \n",
    "            # Histogram segregation of black/white key\n",
    "            # Grayscale has one channel so we use [0]\n",
    "                #Possible values range from 0 to 256\n",
    "            bin_scaler = 4\n",
    "            hist = cv2.calcHist([threshMask], [0], None, [256/bin_scaler], [1, 256])\n",
    "\n",
    "\n",
    "            #Use a Histogram to compute the dominant non-black (i.e. not the background) colour. Use ~90% of this to threshold the image.\n",
    "            T = hist.argmax() * bin_scaler * .9\n",
    "            th1 = threshMask.copy()\n",
    "            th1[th1>T] = 255\n",
    "            th1[th1<T] = 0\n",
    "\n",
    "            #Detect the first set of keys\n",
    "            connectivity = 8\n",
    "            output = cv2.connectedComponentsWithStats(th1, connectivity, cv2.CV_32S)\n",
    "            num_labels_th1 = output[0]\n",
    "            labels_th1 = output[1]\n",
    "            stats_th1 = output[2]\n",
    "            centroids_th1 = output[3]\n",
    "\n",
    "            #Loop through components and determine which ones may be keys\n",
    "            for j in range(1, num_labels_th1):\n",
    "                area = stats_th1[j, cv2.CC_STAT_AREA]\n",
    "                if (20 < area < np.inf): #filtering out relavent detections (the ones big enough to be keys)\n",
    "\n",
    "                    if j > 1:\n",
    "                        ## We've added another label\n",
    "                        num_labels +=1 \n",
    "                        i +=1\n",
    "\n",
    "                    ##Within labels_th1, we have a matrix that is the same size of the image that holds our split component\n",
    "                    #First, cut out the original \"fat\" label\n",
    "                    fat_mask = labels != i\n",
    "                    labels = labels * fat_mask\n",
    "\n",
    "                    #Next, increment each label above the cut one up to accomodate the new label\n",
    "                    higher_mask = labels > i\n",
    "                    labels = labels + higher_mask\n",
    "\n",
    "                    #Then append our segregated key\n",
    "                    new_mask = labels_th1 == j\n",
    "                    new_labels = labels_th1 * new_mask\n",
    "                    new_labels = i * new_labels\n",
    "                    labels = labels + new_labels\n",
    "\n",
    "                    ##Remove the original index for the stats and then add the new one\n",
    "                    if i < len(stats):\n",
    "                        stats = np.delete(stats,i,0)\n",
    "                        stats = np.insert(stats,i,stats_th1[j],0)\n",
    "                    elif j == 1:\n",
    "                        stats = stats[:-1,:]\n",
    "                        stats = np.concatenate((stats,stats_th1[j][None,:]),0)\n",
    "                    else:\n",
    "                        stats = np.concatenate((stats,stats_th1[j][None,:]),0)\n",
    "\n",
    "                    ##Remove the original index for the centroids and then add the new one\n",
    "                    if i < len(centroids):\n",
    "                        centroids = np.delete(centroids,i,0)\n",
    "                        centroids = np.insert(centroids,i,centroids_th1[j],0)\n",
    "                    elif j==1:\n",
    "                        centroids = centroids[:-1,:]\n",
    "                        centroids = np.concatenate((centroids,centroids_th1[j][None,:]),0)  \n",
    "                    else:\n",
    "                        centroids = np.concatenate((centroids,centroids_th1[j][None,:]),0)  \n",
    "                        \n",
    "\n",
    "                        \n",
    "                    print(\"i: {}, stats: {}\".format(i,len(stats)))\n",
    "                    #Plot immediately so indexing doesn't get messed up\n",
    "                    x = stats[i, cv2.CC_STAT_LEFT]\n",
    "                    y = stats[i, cv2.CC_STAT_TOP] + 20 # We cropped out the first 20 pixels\n",
    "                    w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "                    h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "                    area = stats[i, cv2.CC_STAT_AREA]\n",
    "                    (cX, cY) = centroids[i]\n",
    "                    cY = cY + 20 # We cropped out the first 20 pixels\n",
    "                    cv2.rectangle(output_img, (x,y), (x+w, y+h), (255,0,0),1)\n",
    "                    dist_to_edge = h/2 #getting the distance from centroid to bottom edge for better detection later on\n",
    "                    top_dot = cY-dist_to_edge\n",
    "                    bottom_dot = cY+dist_to_edge\n",
    "                    cv2.circle(output_img, (int(cX), int(bottom_dot)), 1, (0,122,255), 3)\n",
    "                    cv2.circle(output_img, (int(cX), int(top_dot)), 1, (0,122,255), 3)\n",
    "\n",
    "                    note = Note(cX, cY+dist_to_edge) #creating note object and adding to list\n",
    "            \n",
    "            \n",
    "                    if ( (int(bottom_dot) >= int(y_cord[0])) and (int(bottom_dot) <= int(y_cord[0])+2) ):\n",
    "                        note_played, index = key_pressed(full_key_list, cX)\n",
    "                        #print(str(note_played) + \" at \" + str(counter))\n",
    "                        keys_timed_update[index].append([elapsed])\n",
    "\n",
    "                    if ( (int(top_dot) >= int(y_cord[0])) and (int(top_dot) <= int(y_cord[0])+2) ):\n",
    "                        note_played, index = key_pressed(full_key_list, cX)\n",
    "                        keys_timed_update[index].append([elapsed])\n",
    "\n",
    "                    note_played, _ = key_pressed(full_key_list, note.centroid_x)\n",
    "                    cv2.putText(output_img, note_played, (int(note.centroid_x), int(note.y_dot)), font, 0.5, (0,255,0), 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #Detect the next set of keys\n",
    "                th2 = threshMask.copy()\n",
    "                th2[th2>T] = 0        \n",
    "                k = 3\n",
    "                blurred_th2 = cv2.GaussianBlur(th2, (k,k), 0)\n",
    "\n",
    "                #Using standard threshold to create contrast between white/black keys\n",
    "                _, th2_notes = cv2.threshold(blurred_th2, 90, 150, cv2.THRESH_BINARY)\n",
    "\n",
    "                #Detect the second set of keys\n",
    "                connectivity = 8\n",
    "                output = cv2.connectedComponentsWithStats(th2_notes, connectivity, cv2.CV_32S)\n",
    "                num_labels_th2 = output[0]\n",
    "                labels_th2 = output[1]\n",
    "                stats_th2 = output[2]\n",
    "                centroids_th2 = output[3]\n",
    "\n",
    "                #Loop through components and determine which ones may be keys\n",
    "                for k in range(1, num_labels_th2):\n",
    "                    area = stats_th2[k, cv2.CC_STAT_AREA]\n",
    "                    if (20 < area < np.inf): #filtering out relavent detections (the ones big enough to be keys)\n",
    "\n",
    "                        if k > 1:\n",
    "                            ## We've added another label\n",
    "                            num_labels +=1 \n",
    "                            i+=1\n",
    "\n",
    "                        ##Within labels_th1, we have a matrix that is the same size of the image that holds our split component\n",
    "                        #For the second key WE DON'T NEED TO CUT anything\n",
    "        #                 fat_mask = labels != i\n",
    "        #                 labels = labels * fat_mask\n",
    "\n",
    "                        #Next, increment each label above the cut one up to accomodate the new label\n",
    "                        higher_mask = labels > i + 1\n",
    "                        labels = labels + higher_mask\n",
    "\n",
    "                        #Then append our segregated key\n",
    "                        new_mask = labels_th2 == k\n",
    "                        new_labels = labels_th2 * new_mask\n",
    "                        new_labels = (i + 1) * new_labels\n",
    "                        labels = labels + new_labels\n",
    "\n",
    "                        ##Add\n",
    "                        if i < len(stats):\n",
    "                            stats = np.insert(stats,(i+1),stats_th2[k],0)                       \n",
    "                        else:\n",
    "                            stats = np.concatenate((stats,stats_th2[k][None,:]),0)\n",
    "                        \n",
    "\n",
    "                        ##Add\n",
    "                        if i < len(centroids):\n",
    "                            centroids = np.insert(centroids,(i+1),centroids_th2[k],0)\n",
    "                        else:\n",
    "                            centroids = np.concatenate((centroids,centroids_th2[k][None,:]),0)\n",
    "\n",
    "                        #Plot immediately so indexing doesn't get messed up\n",
    "                        x = stats[i, cv2.CC_STAT_LEFT]\n",
    "                        y = stats[i, cv2.CC_STAT_TOP] + 20 # We cropped out the first 20 pixels\n",
    "                        w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "                        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "                        area = stats[i, cv2.CC_STAT_AREA]\n",
    "                        (cX, cY) = centroids[i]\n",
    "                        cY = cY + 20 # We cropped out the first 20 pixels\n",
    "                        cv2.rectangle(output_img, (x,y), (x+w, y+h), (255,0,0),1)\n",
    "                        dist_to_edge = h/2 #getting the distance from centroid to bottom edge for better detection later on\n",
    "                        top_dot = cY-dist_to_edge\n",
    "                        bottom_dot = cY+dist_to_edge\n",
    "                        cv2.circle(output_img, (int(cX), int(bottom_dot)), 1, (0,122,255), 3)\n",
    "                        cv2.circle(output_img, (int(cX), int(top_dot)), 1, (0,122,255), 3)\n",
    "\n",
    "                        note = Note(cX, cY+dist_to_edge) #creating note object and adding to list\n",
    "            \n",
    "            \n",
    "                        if ( (int(bottom_dot) >= int(y_cord[0])) and (int(bottom_dot) <= int(y_cord[0])+2) ):\n",
    "                            note_played, index = key_pressed(full_key_list, cX)\n",
    "                            #print(str(note_played) + \" at \" + str(counter))\n",
    "                            keys_timed_update[index].append([elapsed])\n",
    "\n",
    "                        if ( (int(top_dot) >= int(y_cord[0])) and (int(top_dot) <= int(y_cord[0])+2) ):\n",
    "                            note_played, index = key_pressed(full_key_list, cX)\n",
    "                            keys_timed_update[index].append([elapsed])\n",
    "\n",
    "                        note_played, _ = key_pressed(full_key_list, note.centroid_x)\n",
    "                        cv2.putText(output_img, note_played, (int(note.centroid_x), int(note.y_dot)), font, 0.5, (0,255,0), 1)\n",
    "\n",
    "        else:\n",
    "            x = stats[i, cv2.CC_STAT_LEFT]\n",
    "            y = stats[i, cv2.CC_STAT_TOP] + 20 # We cropped out the first 20 pixels\n",
    "            w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "            h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "            area = stats[i, cv2.CC_STAT_AREA]\n",
    "            (cX, cY) = centroids[i]\n",
    "            cY = cY + 20 # We cropped out the first 20 pixels\n",
    "            if (20 < area < np.inf): #filtering out relavent detections (the ones big enough to be black keys)\n",
    "                cv2.rectangle(output_img, (x,y), (x+w, y+h), (255,0,0),1)\n",
    "                dist_to_edge = h/2 #getting the distance from centroid to bottom edge for better detection later on\n",
    "                top_dot = cY-dist_to_edge\n",
    "                bottom_dot = cY+dist_to_edge\n",
    "                cv2.circle(output_img, (int(cX), int(bottom_dot)), 1, (0,122,255), 3)\n",
    "                cv2.circle(output_img, (int(cX), int(top_dot)), 1, (0,122,255), 3)\n",
    "\n",
    "                note = Note(cX, cY+dist_to_edge) #creating note object and adding to list\n",
    "            \n",
    "                if ( (int(bottom_dot) >= int(y_cord[0])) and (int(bottom_dot) <= int(y_cord[0])+2) ):\n",
    "                    note_played, index = key_pressed(full_key_list, cX)\n",
    "                    #print(str(note_played) + \" at \" + str(counter))\n",
    "                    keys_timed_update[index].append([elapsed])\n",
    "\n",
    "                if ( (int(top_dot) >= int(y_cord[0])) and (int(top_dot) <= int(y_cord[0])+2) ):\n",
    "                    note_played, index = key_pressed(full_key_list, cX)\n",
    "                    keys_timed_update[index].append([elapsed])\n",
    "\n",
    "                note_played, _ = key_pressed(full_key_list, note.centroid_x)\n",
    "                cv2.putText(output_img, note_played, (int(note.centroid_x), int(note.y_dot)), font, 0.5, (0,255,0), 1)\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    \n",
    "    #Show the frame + drawn rectangle\n",
    "    cv2.imshow(\"Video\", output_img)\n",
    "\n",
    "    #Can break early by pressing \"q\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "# print(keys_timed_update)    \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "\n",
    "for i in range (len(keys_timed_update)):\n",
    "    temp = []\n",
    "    temp.append(keys_timed_update[i][0])\n",
    "    if (len(keys_timed_update[i]) > 1):\n",
    "        for j in range(1,len(keys_timed_update[i])):\n",
    "            temp.append(keys_timed_update[i][j][0])\n",
    "\n",
    "    new_list.append(temp)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(new_list)\n",
    "df.to_csv('notes_info.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "env_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
